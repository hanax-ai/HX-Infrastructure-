# HX-Infrastructure API Gateway - Shared Model Definitions
# This file contains the canonical definitions for all models and load balancer groups
# All backup configs should reference these definitions to ensure consistency

# --- API Base URL Configuration ---
# Centralized server endpoints with environment variable support
api_bases:
  orc_base: &orc_api_base "${ORC_API_BASE:-http://192.168.10.31:11434}"
  llm01_base: &llm01_api_base "${LLM01_API_BASE:-http://192.168.10.29:11434}"
  llm02_base: &llm02_api_base "${LLM02_API_BASE:-http://192.168.10.28:11434}"

# --- Embedding Models (ORC Server) ---
embedding_models: &embedding_models
  - model_name: emb-premium
    litellm_params: { model: "ollama/mxbai-embed-large", api_base: *orc_api_base }
  - model_name: emb-perf
    litellm_params: { model: "ollama/nomic-embed-text",  api_base: *orc_api_base }
  - model_name: emb-light
    litellm_params: { model: "ollama/all-minilm",       api_base: *orc_api_base }

# --- LLM-01 Models (192.168.10.29) ---
llm01_models: &llm01_models
  - model_name: llm01-llama3.2-3b
    litellm_params: { model: "ollama/llama3.2:3b", api_base: *llm01_api_base }
  - model_name: llm01-qwen3-1.7b
    litellm_params: { model: "ollama/qwen3:1.7b", api_base: *llm01_api_base }
  - model_name: llm01-mistral-small3.2
    litellm_params: { model: "ollama/mistral-small3.2:latest", api_base: *llm01_api_base }

# --- LLM-02 Models (192.168.10.28) ---
llm02_models: &llm02_models
  - model_name: llm02-cogito-32b
    litellm_params: { model: "ollama/cogito:32b", api_base: *llm02_api_base }
  - model_name: llm02-deepcoder-14b
    litellm_params: { model: "ollama/deepcoder:14b", api_base: *llm02_api_base }
  - model_name: llm02-dolphin3-8b
    litellm_params: { model: "ollama/dolphin3:8b", api_base: *llm02_api_base }
  - model_name: llm02-gemma2-2b
    litellm_params: { model: "ollama/gemma2:2b", api_base: *llm02_api_base }
  - model_name: llm02-phi3
    litellm_params: { model: "ollama/phi3:latest", api_base: *llm02_api_base }

# --- Load Balancer Groups (Canonical Definitions) ---
load_balancer_groups: &load_balancer_groups
  # Speed-optimized (small, fast models)
  - model_name: hx-chat-fast
    litellm_params: { model: "ollama/qwen3:1.7b", api_base: *llm01_api_base }
    description: "Speed optimized (Qwen3 1.7B)"
  
  # Balanced performance
  - model_name: hx-chat
    litellm_params: { model: "ollama/llama3.2:3b", api_base: *llm01_api_base }
    description: "Balanced performance (Llama 3.2 3B)"
  
  # Code-specialized
  - model_name: hx-chat-code
    litellm_params: { model: "ollama/deepcoder:14b", api_base: *llm02_api_base }
    description: "Code specialized (DeepCoder 14B)"
  
  # High-quality reasoning
  - model_name: hx-chat-premium
    litellm_params: { model: "ollama/cogito:32b", api_base: *llm02_api_base }
    description: "Premium quality (Cogito 32B)"
  
  # Creative/conversational
  - model_name: hx-chat-creative
    litellm_params: { model: "ollama/dolphin3:8b", api_base: *llm02_api_base }
    description: "Creative tasks (Dolphin3 8B)"

# --- Complete Model List (All Models Combined) ---
complete_model_list: &complete_model_list
  # Embeddings
  - model_name: emb-premium
    litellm_params: { model: "ollama/mxbai-embed-large", api_base: *orc_api_base }
  - model_name: emb-perf
    litellm_params: { model: "ollama/nomic-embed-text",  api_base: *orc_api_base }
  - model_name: emb-light
    litellm_params: { model: "ollama/all-minilm",       api_base: *orc_api_base }
  # LLM-01
  - model_name: llm01-llama3.2-3b
    litellm_params: { model: "ollama/llama3.2:3b", api_base: *llm01_api_base }
  - model_name: llm01-qwen3-1.7b
    litellm_params: { model: "ollama/qwen3:1.7b", api_base: *llm01_api_base }
  - model_name: llm01-mistral-small3.2
    litellm_params: { model: "ollama/mistral-small3.2:latest", api_base: *llm01_api_base }
  # LLM-02
  - model_name: llm02-cogito-32b
    litellm_params: { model: "ollama/cogito:32b", api_base: *llm02_api_base }
  - model_name: llm02-deepcoder-14b
    litellm_params: { model: "ollama/deepcoder:14b", api_base: *llm02_api_base }
  - model_name: llm02-dolphin3-8b
    litellm_params: { model: "ollama/dolphin3:8b", api_base: *llm02_api_base }
  - model_name: llm02-gemma2-2b
    litellm_params: { model: "ollama/gemma2:2b", api_base: *llm02_api_base }
  - model_name: llm02-phi3
    litellm_params: { model: "ollama/phi3:latest", api_base: *llm02_api_base }
  # Load Balancers
  - model_name: hx-chat-fast
    litellm_params: { model: "ollama/qwen3:1.7b", api_base: *llm01_api_base }
    description: "Speed optimized (Qwen3 1.7B)"
  - model_name: hx-chat
    litellm_params: { model: "ollama/llama3.2:3b", api_base: *llm01_api_base }
    description: "Balanced performance (Llama 3.2 3B)"
  - model_name: hx-chat-code
    litellm_params: { model: "ollama/deepcoder:14b", api_base: *llm02_api_base }
    description: "Code specialized (DeepCoder 14B)"
  - model_name: hx-chat-premium
    litellm_params: { model: "ollama/cogito:32b", api_base: *llm02_api_base }
    description: "Premium quality (Cogito 32B)"
  - model_name: hx-chat-creative
    litellm_params: { model: "ollama/dolphin3:8b", api_base: *llm02_api_base }
    description: "Creative tasks (Dolphin3 8B)"
