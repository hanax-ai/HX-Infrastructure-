# Extended Configuration with Centralized API Base Configuration
# This configuration uses parameterized endpoints for flexible deployment

general_settings:
  master_key: ${MASTER_KEY:?MASTER_KEY environment variable must be set}
  background_health_checks: false

# --- API Base URL Configuration ---
# Centralized server endpoints with environment variable support
api_bases:
  orc_base: &orc_api_base "${ORC_API_BASE:-http://192.168.10.31:11434}"
  llm01_base: &llm01_api_base "${LLM01_API_BASE:-http://192.168.10.29:11434}"
  llm02_base: &llm02_api_base "${LLM02_API_BASE:-http://192.168.10.28:11434}"

model_list:
  # --- Embeddings (orc - configurable via ORC_API_BASE) ---
  - model_name: emb-premium
    litellm_params: { model: "ollama/mxbai-embed-large", api_base: *orc_api_base }
  - model_name: emb-perf
    litellm_params: { model: "ollama/nomic-embed-text",  api_base: *orc_api_base }
  - model_name: emb-light
    litellm_params: { model: "ollama/all-minilm",       api_base: *orc_api_base }

  # --- LLM-01 Models (configurable via LLM01_API_BASE) ---
  - model_name: llm01-llama3.2-3b
    litellm_params: { model: "ollama/llama3.2:3b", api_base: *llm01_api_base }
  - model_name: llm01-qwen3-1.7b
    litellm_params: { model: "ollama/qwen3:1.7b", api_base: *llm01_api_base }
  - model_name: llm01-mistral-small3.2
    litellm_params: { model: "ollama/mistral-small3.2:latest", api_base: *llm01_api_base }

  # --- LLM-02 Models (configurable via LLM02_API_BASE) ---
  - model_name: llm02-phi3
    litellm_params: { model: "ollama/phi3:latest", api_base: *llm02_api_base }
  - model_name: llm02-gemma2-2b
    litellm_params: { model: "ollama/gemma2:2b",   api_base: *llm02_api_base }

  # --- Load Balancer Groups (Extended Configuration Subset) ---
  # Balanced performance
  - model_name: hx-chat
    litellm_params: { model: "ollama/llama3.2:3b", api_base: *llm01_api_base }
  
  # Speed-optimized
  - model_name: hx-chat-fast
    litellm_params: { model: "ollama/qwen3:1.7b", api_base: *llm01_api_base }
  
  # High-quality reasoning
  - model_name: hx-chat-premium
    litellm_params: { model: "ollama/mistral-small3.2:latest", api_base: *llm01_api_base }
